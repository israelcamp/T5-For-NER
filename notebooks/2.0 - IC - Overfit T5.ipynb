{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZWJ_Yo0DnRLN"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DoywPEf3n2xH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.make_conll2003 import get_example_sets, InputExample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "Some of the steps might be done twice during the course of this notebook, but its for debugging purposes.\n",
    "\n",
    "Final codes will not have duplicities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3104,
     "status": "ok",
     "timestamp": 1589651850137,
     "user": {
      "displayName": "Israel Campiotti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghxy8zYBrIXP82xQY8KlmWXPR9PJmyF2cG5YA6I=s64",
      "userId": "02000835910791656164"
     },
     "user_tz": 180
    },
    "id": "85UsT0HRn93D",
    "outputId": "40e6a0e5-dbd0-4c39-bf1c-54db55c4b0f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'valid', 'test'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folderpath = '../data/conll2003/'\n",
    "sets_dict = get_example_sets(folderpath)\n",
    "sets_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hBv1x7dpoIgN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Source: EU rejects German call to boycott British lamb .\n",
       "Target: EU <ORG> rejects <O> German <MISC> call <O> to <O> boycott <O> British <MISC> lamb <O> . <O>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sets_dict['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NER_LABELS = [\n",
    "    '<O>',\n",
    "    '<PER>',\n",
    "    '<ORG>',\n",
    "    '<LOC>',\n",
    "    '<MISC>'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = 't5-small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens(NER_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities_from_token_ids(token_ids:List[int], tokenizer: T5Tokenizer, NER_LABELS: List[str]):\n",
    "    entities = {k:[] for k in NER_LABELS}\n",
    "    current_entity = []\n",
    "    sequence_tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "    for token in sequence_tokens:\n",
    "        if token in NER_LABELS:\n",
    "            entities[token].append(tokenizer.convert_tokens_to_string(current_entity))\n",
    "            current_entity.clear()\n",
    "        else:\n",
    "            current_entity.append(token)\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeature:\n",
    "    \n",
    "    def __init__(self, source_token_ids, target_token_ids, attention_mask, example=None):\n",
    "        self.source_token_ids = source_token_ids\n",
    "        self.target_token_ids = target_token_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.example = example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_example_to_feature(example: InputExample, tokenizer:T5Tokenizer, max_length:int=512, prefix:str='Extract Entities:') -> InputFeature:\n",
    "    source = f'{prefix} {example.source}'\n",
    "    target = example.target\n",
    "    \n",
    "    source_tokens = tokenizer.tokenize(source)\n",
    "    target_tokens = tokenizer.tokenize(target)\n",
    "    \n",
    "    _max = max_length - 1 # we will add eos token to the end of both lists\n",
    "    source_tokens = source_tokens[:min(len(source_tokens), _max)]\n",
    "    target_tokens = target_tokens[:min(len(target_tokens), _max)]\n",
    "    \n",
    "    # adding the eos\n",
    "    source_tokens += [tokenizer.eos_token]\n",
    "    target_tokens += [tokenizer.eos_token]\n",
    "    \n",
    "    # attention mask\n",
    "    attention_mask = [1] * len(source_tokens)\n",
    "    \n",
    "    # padding\n",
    "    missing_source = max(0, max_length - len(source_tokens))\n",
    "    missing_target = max(0, max_length - len(target_tokens))\n",
    "    source_tokens += missing_source * [tokenizer.pad_token]\n",
    "    target_tokens += missing_target * [tokenizer.pad_token]\n",
    "    attention_mask += missing_source * [0]\n",
    "    \n",
    "    source_token_ids = tokenizer.convert_tokens_to_ids(source_tokens)\n",
    "    target_token_ids = tokenizer.convert_tokens_to_ids(target_tokens)\n",
    "    \n",
    "    assert max_length == len(source_tokens), f'Max length is {max_length} and len(source_tokens) is {len(source_tokens)}'\n",
    "    assert max_length == len(target_tokens), f'Max length is {max_length} and len(target_tokens) is {len(target_tokens)}'\n",
    "    assert max_length == len(attention_mask), f'Max length is {max_length} and len(attention_mask) is {len(attention_mask)}'\n",
    "    \n",
    "    return InputFeature(source_token_ids, target_token_ids, attention_mask, example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples: List[InputExample], tokenizer:T5Tokenizer, max_length:int=512, prefix:str='Extract Entities:')->List[InputFeature]:\n",
    "    return [convert_example_to_feature(example, tokenizer, max_length, prefix) for example in examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_example_sets_to_features_sets(examples_sets: Dict[str, List[InputExample]], tokenizer:T5Tokenizer, max_length:int=512, prefix:str='Extract Entities:') -> Dict[str, List[InputFeature]]:\n",
    "    return {\n",
    "        key:convert_examples_to_features(examples, tokenizer, max_length, prefix) for key, examples in examples_sets.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_sets = convert_example_sets_to_features_sets(sets_dict, tokenizer, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = features_sets['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Source: EU rejects German call to boycott British lamb .\n",
       "Target: EU <ORG> rejects <O> German <MISC> call <O> to <O> boycott <O> British <MISC> lamb <O> . <O>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Extract Entities: EU rejects German call to boycott British lamb.',\n",
       " 'EU <ORG> rejects <O> German <MISC> call <O> to <O> boycott <O> British <MISC> lamb <O>. <O> ')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(feature.source_token_ids), tokenizer.decode(feature.target_token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        \n",
    "    def __len__(self,):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5NERDataset(FeaturesDataset):\n",
    "    \n",
    "    def __init__(self, features, *args, tokenizer=None, NER_LABELS=None, **kwargs):\n",
    "        super().__init__(features, *args, **kwargs)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.NER_LABELS = NER_LABELS\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        feat = self.features[idx]\n",
    "        input_ids = torch.tensor(feat.source_token_ids, dtype=torch.long)\n",
    "        attention_mask = torch.tensor(feat.attention_mask, dtype=torch.long)\n",
    "        lm_labels = torch.tensor(feat.target_token_ids, dtype=torch.long)\n",
    "        \n",
    "        outputs = (input_ids, attention_mask, lm_labels)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_debug = T5NERDataset(features_sets['train'][:10])\n",
    "dl_debug = DataLoader(ds_debug, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, attention_mask, lm_labels = next(iter(dl_debug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 128]), torch.Size([2, 128]), torch.Size([2, 128]))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape, attention_mask.shape, lm_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5ForNERWithPL(T5ForConditionalGeneration, pl.LightningModule):\n",
    "    \n",
    "    @classmethod\n",
    "    def from_pretrained(cls, pretrained_model_name_or_path, **kwargs) -> \"PretrainedConfig\":\n",
    "        cls.pretrained_model_name_or_path = pretrained_model_name_or_path\n",
    "        return super(T5ForConditionalGeneration, cls).from_pretrained(pretrained_model_name_or_path, **kwargs)\n",
    "    \n",
    "    def _handle_batch(self, batch):\n",
    "        input_ids, attention_mask, lm_labels = batch\n",
    "        outputs = self(input_ids=input_ids, attention_mask=attention_mask, lm_labels=lm_labels)\n",
    "        return outputs\n",
    "    \n",
    "    def _average_key(self, outputs, key):\n",
    "        return torch.mean(torch.stack([o[key] for o in outputs]).float())\n",
    "    \n",
    "    def train_step(self, batch):\n",
    "        outputs = self._handle_batch(batch)\n",
    "        return {'loss': outputs[0]}\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        outputs = self._handle_batch(batch)\n",
    "        return {'val_loss': outputs[0]}\n",
    "    \n",
    "    def test_step(self, batch):\n",
    "        outputs = self._handle_batch(batch)\n",
    "        return {'test_loss': outputs[0]}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        loss_avg = self._average_key(outputs, 'val_loss')\n",
    "        return {'val_loss': loss_avg}\n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        loss_avg = self._average_key(outputs, 'test_loss')\n",
    "        return {'test_loss': loss_avg}\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5ForConll2003(T5ForNERWithPL):\n",
    "    \n",
    "    @property\n",
    "    def pretrained_model_name(self,):\n",
    "        return self.pretrained_model_name_or_path\n",
    "    \n",
    "    @property\n",
    "    def datapath(self,):\n",
    "        return '../data/conll2003/'\n",
    "    \n",
    "    @property\n",
    "    def max_length(self,):\n",
    "        return 128\n",
    "    \n",
    "    @property\n",
    "    def batch_size(self,):\n",
    "        return 2\n",
    "    \n",
    "    @property\n",
    "    def num_workers(self,):\n",
    "        return 2\n",
    "    \n",
    "    def get_examples(self,):\n",
    "        return get_example_sets(self.datapath)\n",
    "    \n",
    "    def get_tokenizer(self,):\n",
    "        return T5Tokenizer.from_pretrained(self.pretrained_model_name)\n",
    "    \n",
    "    def get_features(self,examples, tokenizer, max_length):\n",
    "        return convert_example_sets_to_features_sets(examples, tokenizer, max_length=max_length)\n",
    "    \n",
    "    def get_datasets(self, features):\n",
    "        return features['train'], features['valid'], features['test']\n",
    "    \n",
    "    def prepare_data(self,):\n",
    "        examples = self.get_example_sets()\n",
    "        self.tokenizer = self.get_tokenizer()\n",
    "        features = self.get_features(examples, self.tokenizer, max_length=self.max_length)\n",
    "        self.train_dataset, self.val_dataset, self.test_dataset = self.get_datasets(features)\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        raise DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        raise DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        raise DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        raise torch.optim.Adam(self.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConll2003.from_pretrained(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask, lm_labels=lm_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, tensor(13.1443))"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs), outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_token_ids = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_token_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<extra_id_0>:',\n",
       " 'Extract Entities: EU rejects German call to boycott British lamb.',\n",
       " 'EU <ORG> rejects <O> German <MISC> call <O> to <O> boycott <O> British <MISC> lamb <O>. <O> ')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "tokenizer.decode(predicted_token_ids[i]), tokenizer.decode(input_ids[i]), tokenizer.decode(lm_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EU <ORG> rejects <O> German <MISC> call <O> to <O> boycott <O> British <MISC> lamb <O>. <O> '"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = tokenizer.decode(lm_labels[i])\n",
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOEQFs1hQw2f4//XEv2338X",
   "collapsed_sections": [],
   "mount_file_id": "1mwxggUBK86BB6y_2WfG7apqZr9bd1I-k",
   "name": "First T5 training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:t5ner]",
   "language": "python",
   "name": "conda-env-t5ner-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
