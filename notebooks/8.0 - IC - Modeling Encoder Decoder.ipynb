{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EncoderDecoderModel, BertTokenizer, PreTrainedModel\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Optional\n",
    "\n",
    "from transformers.configuration_encoder_decoder import EncoderDecoderConfig\n",
    "from transformers.configuration_utils import PretrainedConfig\n",
    "from transformers.modeling_utils import PreTrainedModel\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.modeling_ner import ModelForNERBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseWithPL(PreTrainedModel, pl.LightningModule):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoderForNER(ModelForNERBase, BaseWithPL):\n",
    "\n",
    "    def __init__(self, config=None, encoder=None, decoder=None, hparams=None):\n",
    "        \n",
    "        assert config is not None or (\n",
    "            encoder is not None and decoder is not None\n",
    "        ), \"Either a configuration or an Encoder and a decoder has to be provided\"\n",
    "        if config is None:\n",
    "            config = EncoderDecoderConfig.from_encoder_decoder_configs(encoder.config, decoder.config)\n",
    "        else:\n",
    "            assert isinstance(config, self.config_class), \"config: {} has to be of type {}\".format(\n",
    "                config, self.config_class\n",
    "            )\n",
    "        # initialize with config\n",
    "        super(BaseWithPL, self).__init__(config)\n",
    "\n",
    "        if encoder is None:\n",
    "            from transformers import AutoModel\n",
    "\n",
    "            encoder = AutoModel.from_config(config.encoder)\n",
    "\n",
    "        if decoder is None:\n",
    "            from transformers import AutoModelWithLMHead\n",
    "\n",
    "            decoder = AutoModelWithLMHead.from_config(config.decoder)\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        assert (\n",
    "            self.encoder.get_output_embeddings() is None\n",
    "        ), \"The encoder {} should not have a LM Head. Please use a model without LM Head\"\n",
    "\n",
    "\n",
    "        self.hparams = hparams\n",
    "\n",
    "        self.tokenizer = self.get_tokenizer()\n",
    "        # creating the loss\n",
    "#         self._token_weights = self._create_token_weights()\n",
    "\n",
    "        self.train_dataset = None\n",
    "        self.val_dataset = None\n",
    "        self.test_dataset = None\n",
    "        \n",
    "    def tie_weights(self):\n",
    "        # for now no weights tying in encoder-decoder\n",
    "        pass\n",
    "\n",
    "    def get_encoder(self):\n",
    "        return self.encoder\n",
    "\n",
    "    def get_decoder(self):\n",
    "        return self.decoder\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.encoder.get_input_embeddings()\n",
    "\n",
    "\n",
    "    def get_output_embeddings(self):\n",
    "        return self.decoder.get_output_embeddings()\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def from_encoder_decoder_pretrained(\n",
    "        cls,\n",
    "        encoder_pretrained_model_name_or_path: str = None,\n",
    "        decoder_pretrained_model_name_or_path: str = None,\n",
    "        hparams=None,\n",
    "        *model_args,\n",
    "        **kwargs\n",
    "    ) -> PreTrainedModel:\n",
    "\n",
    "        kwargs_encoder = {\n",
    "            argument[len(\"encoder_\") :]: value for argument, value in kwargs.items() if argument.startswith(\"encoder_\")\n",
    "        }\n",
    "\n",
    "        kwargs_decoder = {\n",
    "            argument[len(\"decoder_\") :]: value for argument, value in kwargs.items() if argument.startswith(\"decoder_\")\n",
    "        }\n",
    "\n",
    "        # Load and initialize the encoder and decoder\n",
    "        # The distinction between encoder and decoder at the model level is made\n",
    "        # by the value of the flag `is_decoder` that we need to set correctly.\n",
    "        encoder = kwargs_encoder.pop(\"model\", None)\n",
    "        if encoder is None:\n",
    "            assert (\n",
    "                encoder_pretrained_model_name_or_path is not None\n",
    "            ), \"If `model` is not defined as an argument, a `encoder_pretrained_model_name_or_path` has to be defined\"\n",
    "            from transformers.modeling_auto import AutoModel\n",
    "\n",
    "            encoder = AutoModel.from_pretrained(encoder_pretrained_model_name_or_path, *model_args, **kwargs_encoder)\n",
    "        encoder.config.is_decoder = False\n",
    "\n",
    "        decoder = kwargs_decoder.pop(\"model\", None)\n",
    "        if decoder is None:\n",
    "            assert (\n",
    "                decoder_pretrained_model_name_or_path is not None\n",
    "            ), \"If `decoder_model` is not defined as an argument, a `decoder_pretrained_model_name_or_path` has to be defined\"\n",
    "            from transformers.modeling_auto import AutoModelWithLMHead\n",
    "\n",
    "            if \"config\" not in kwargs_decoder:\n",
    "                from transformers import AutoConfig\n",
    "\n",
    "                decoder_config = AutoConfig.from_pretrained(decoder_pretrained_model_name_or_path)\n",
    "                if decoder_config.is_decoder is False:\n",
    "                    logger.info(\n",
    "                        f\"Initializing {decoder_pretrained_model_name_or_path} as a decoder model. Cross attention layers are added to {decoder_pretrained_model_name_or_path} and randomly initialized if {decoder_pretrained_model_name_or_path}'s architecture allows for cross attention layers.\"\n",
    "                    )\n",
    "                    decoder_config.is_decoder = True\n",
    "\n",
    "                kwargs_decoder[\"config\"] = decoder_config\n",
    "\n",
    "            if kwargs_decoder[\"config\"].is_decoder is False:\n",
    "                logger.warning(\n",
    "                    f\"Decoder model {decoder_pretrained_model_name_or_path} is not initialized as a decoder. In order to initialize {decoder_pretrained_model_name_or_path} as a decoder, make sure that the attribute `is_decoder` of `decoder_config` passed to `.from_encoder_decoder_pretrained(...)` is set to `True` or do not pass a `decoder_config` to `.from_encoder_decoder_pretrained(...)`\"\n",
    "                )\n",
    "\n",
    "            decoder = AutoModelWithLMHead.from_pretrained(decoder_pretrained_model_name_or_path, **kwargs_decoder)\n",
    "\n",
    "        return cls(encoder=encoder, decoder=decoder, hparams=hparams)\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        inputs_embeds=None,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        encoder_outputs=None,\n",
    "        decoder_input_ids=None,\n",
    "        decoder_attention_mask=None,\n",
    "        decoder_head_mask=None,\n",
    "        decoder_inputs_embeds=None,\n",
    "        labels=None,\n",
    "        lm_labels=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "\n",
    "        kwargs_encoder = {argument: value for argument, value in kwargs.items() if not argument.startswith(\"decoder_\")}\n",
    "\n",
    "        kwargs_decoder = {\n",
    "            argument[len(\"decoder_\") :]: value for argument, value in kwargs.items() if argument.startswith(\"decoder_\")\n",
    "        }\n",
    "\n",
    "        if encoder_outputs is None:\n",
    "            encoder_outputs = self.encoder(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                inputs_embeds=inputs_embeds,\n",
    "                head_mask=head_mask,\n",
    "                **kwargs_encoder,\n",
    "            )\n",
    "\n",
    "        hidden_states = encoder_outputs[0]\n",
    "\n",
    "        # Decode\n",
    "        decoder_outputs = self.decoder(\n",
    "            input_ids=decoder_input_ids,\n",
    "            inputs_embeds=decoder_inputs_embeds,\n",
    "            attention_mask=decoder_attention_mask,\n",
    "            encoder_hidden_states=hidden_states,\n",
    "            encoder_attention_mask=attention_mask,\n",
    "            head_mask=decoder_head_mask,\n",
    "            lm_labels=lm_labels,\n",
    "#             labels=labels,\n",
    "            **kwargs_decoder,\n",
    "        )\n",
    "\n",
    "        return decoder_outputs + encoder_outputs\n",
    "\n",
    "\n",
    "    def prepare_inputs_for_generation(self, input_ids, past, attention_mask, **kwargs):\n",
    "        assert past is not None, \"past has to be defined for encoder_outputs\"\n",
    "\n",
    "        # first step\n",
    "        if type(past) is tuple:\n",
    "            encoder_outputs = past\n",
    "        else:\n",
    "            encoder_outputs = (past,)\n",
    "\n",
    "        decoder_inputs = self.decoder.prepare_inputs_for_generation(input_ids)\n",
    "\n",
    "        return {\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"decoder_attention_mask\": decoder_inputs[\"attention_mask\"],\n",
    "            \"decoder_input_ids\": decoder_inputs[\"input_ids\"],\n",
    "            \"encoder_outputs\": encoder_outputs,\n",
    "        }\n",
    "\n",
    "    def _reorder_cache(self, past, beam_idx):\n",
    "        # as a default encoder-decoder models do not re-order the past.\n",
    "        # TODO(PVP): might have to be updated, e.g. if GPT2 is to be used as a decoder\n",
    "        return past\n",
    "        \n",
    "    def _handle_batch(self, batch):\n",
    "        batch = self.trim_batch(batch)\n",
    "        input_ids, attention_mask, lm_labels = batch\n",
    "        outputs = self(input_ids=input_ids,\n",
    "                       decoder_input_ids=input_ids,\n",
    "                       attention_mask=attention_mask,\n",
    "                       lm_labels=lm_labels)\n",
    "        return outputs\n",
    "    \n",
    "    @staticmethod\n",
    "    def trim_matrix(mat, value):\n",
    "        eq_val = (mat == value).float()\n",
    "        eq_val = eq_val.cumsum(-1)\n",
    "        index = torch.nonzero(eq_val == 1.)\n",
    "        if len(index) and len(index) == len(mat):\n",
    "            index = index[:, 1].max().item()\n",
    "        else:\n",
    "            index = mat.shape[-1]\n",
    "        return index\n",
    "    \n",
    "    def trim_batch(self, batch):\n",
    "        input_ids, attention_mask, lm_labels = batch\n",
    "        input_ids_index = self.trim_matrix(input_ids, self.config.encoder.pad_token_id)\n",
    "        lm_labels_index = self.trim_matrix(lm_labels, -100)\n",
    "        \n",
    "        index = max(input_ids_index, lm_labels_index)\n",
    "        \n",
    "        attention_mask = attention_mask[:, :index]\n",
    "        input_ids = input_ids[:, :index]\n",
    "        lm_labels = lm_labels[:, :index]\n",
    "        return input_ids, attention_mask, lm_labels\n",
    "        \n",
    "    def get_tokenizer(self,):\n",
    "        pretrained_model = self.get_value_or_default_hparam(\n",
    "            'pretrained_model', 'bert-base-cased')\n",
    "        return BertTokenizer.from_pretrained(pretrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conll2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.modeling_conll2003 import Conll2003Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoderForConll2003(Conll2003Base, EncoderDecoderForNER):\n",
    "    \n",
    "    def get_tokenizer(self,):\n",
    "        tokenizer = super().get_tokenizer()\n",
    "#         tokenizer.add_tokens(self.entities_tokens)\n",
    "        return tokenizer\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"end_token\": 'sep',\n",
    "    'pretrained_model': 'bert-base-uncased',\n",
    "    'labels_mode': 'words',\n",
    "    'merge_O': True\n",
    "}\n",
    "hparams = Namespace(**hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncoderDecoderForConll2003.from_encoder_decoder_pretrained('bert-base-uncased', 'bert-base-uncased', hparams=hparams) # initialize Bert2Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = model.get_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Source: EU rejects German call to boycott British lamb .\n",
       "Target: EU [Organization] rejects [Other] German [Miscellaneous] call to boycott [Other] British [Miscellaneous] lamb . [Other]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch = next(iter(model.train_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, attention_mask, lm_labels = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1587428207430/work/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(11.1760, grad_fn=<NllLossBackward>),\n",
       " tensor([[[-4.2656, -4.5210, -4.5161,  ..., -4.8522, -5.3251, -5.5572],\n",
       "          [-2.4787, -2.8884, -2.7178,  ..., -3.6082, -3.3271, -6.9371],\n",
       "          [-7.8276, -7.6111, -7.9250,  ..., -6.8847, -8.1065, -2.6276],\n",
       "          ...,\n",
       "          [-4.9362, -5.9066, -5.5162,  ..., -7.5794, -5.6245, -5.0047],\n",
       "          [-4.2324, -5.2047, -4.8554,  ..., -6.9375, -5.1227, -3.6019],\n",
       "          [-2.9852, -3.9339, -3.6173,  ..., -6.0910, -3.8285, -2.0919]],\n",
       " \n",
       "         [[-6.5920, -6.4046, -6.6076,  ..., -6.9532, -6.5586, -1.2814],\n",
       "          [-5.3631, -5.4862, -5.3050,  ..., -6.1829, -5.0344, -3.2574],\n",
       "          [-8.7467, -8.8679, -8.9009,  ..., -8.8365, -8.4121, -2.8041],\n",
       "          ...,\n",
       "          [-3.8576, -4.6478, -4.2220,  ..., -6.9258, -5.2491, -0.6430],\n",
       "          [-3.3311, -4.0553, -3.6056,  ..., -5.8988, -4.6884, -0.2115],\n",
       "          [-2.2159, -2.9656, -2.5046,  ..., -4.7028, -3.5162,  0.3270]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[-0.3623, -0.0200, -0.0618,  ..., -0.4959,  0.2672,  0.3933],\n",
       "          [ 0.3559,  0.0958, -0.1176,  ..., -0.2330,  0.6896, -0.0665],\n",
       "          [-0.6269,  0.1778, -0.4894,  ..., -0.3911,  0.1567, -0.2760],\n",
       "          ...,\n",
       "          [-0.3156, -0.5671,  0.0670,  ...,  0.0635,  0.4181,  0.2233],\n",
       "          [-0.2711, -0.4792,  0.1625,  ...,  0.0279,  0.3715,  0.1984],\n",
       "          [-0.1124, -0.1067,  0.2607,  ..., -0.2137,  0.1256,  0.1978]],\n",
       " \n",
       "         [[-0.2280, -0.1932, -0.3352,  ..., -0.5752,  0.0964,  0.6614],\n",
       "          [ 0.3044, -0.1251, -0.1106,  ..., -0.2765,  0.2988,  0.1608],\n",
       "          [-0.5046,  0.1030, -0.8872,  ..., -0.5913,  0.2879,  0.1014],\n",
       "          ...,\n",
       "          [-0.3041, -0.3020, -0.0246,  ..., -0.1648,  0.2683,  0.1264],\n",
       "          [-0.3931, -0.5404, -0.3494,  ..., -0.0380,  0.3645,  0.1459],\n",
       "          [-0.2512, -0.3244, -0.1512,  ..., -0.1549,  0.3245,  0.1947]]],\n",
       "        grad_fn=<NativeLayerNormBackward>),\n",
       " tensor([[-0.8882, -0.4999, -0.9709,  ..., -0.8672, -0.6460,  0.7382],\n",
       "         [-0.9175, -0.6032, -0.9210,  ..., -0.8215, -0.7139,  0.8281]],\n",
       "        grad_fn=<TanhBackward>))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._handle_batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outs = model(input_ids=input_ids, attention_mask=attention_mask, decoder_input_ids=input_ids, lm_labels=lm_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.tokenizer.convert_ids_to_tokens(1031)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:t5ner]",
   "language": "python",
   "name": "conda-env-t5ner-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
