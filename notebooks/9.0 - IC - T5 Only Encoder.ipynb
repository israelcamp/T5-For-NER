{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import T5Tokenizer, T5Model\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from src.models.modeling_conll2003 import T5ForConll2003\n",
    "from src.models.modeling_utils import ConfigBase\n",
    "from src.models.modeling_ner import ModelForNERBase\n",
    "from src.models.evaluate import get_entities_from_tokens\n",
    "from src.data.make_conll2003 import get_example_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConll2003.from_pretrained('t5-small', hparams=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = model.get_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = examples['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Source: Peter Blackburn\n",
       "Target: Peter Blackburn <PER>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTITIES_TOKENS = [\n",
    "            '<O>',\n",
    "            '<PER>',\n",
    "            '<ORG>',\n",
    "            '<LOC>',\n",
    "            '<MISC>',\n",
    "            '<Ent>'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_TOKENS = [\n",
    "    \"O\", \"B-MISC\", \"I-MISC\", \"B-PER\", \"I-PER\", \"B-ORG\", \"I-ORG\", \"B-LOC\", \"I-LOC\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeatures:\n",
    "    \n",
    "    def __init__(self, input_ids, attention_mask, label_ids, prediction_mask):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.label_ids = label_ids\n",
    "        self.prediction_mask = prediction_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_example_to_features(example, tokenizer, max_length):\n",
    "    source = example.source\n",
    "    target = example.target\n",
    "    \n",
    "    source_tokens = tokenizer.tokenize(source)\n",
    "    target_tokens = tokenizer.tokenize(target)\n",
    "    \n",
    "    entities = get_entities_from_tokens(target_tokens, tokenizer, ENTITIES_TOKENS, length=len(source_tokens))\n",
    "        \n",
    "    assert len(source_tokens) == len(entities), f'{example}'\n",
    "    \n",
    "    source_tokens = source_tokens[:min(len(source_tokens), max_length - 1)]\n",
    "    entities = entities[:min(len(source_tokens), max_length - 1)]\n",
    "    \n",
    "    # attention and prediction mask\n",
    "    attention_mask = [1] * len(source_tokens)\n",
    "    \n",
    "    prediction_mask = []\n",
    "    for word in source.split(' '):\n",
    "        tokens = tokenizer.tokenize(word)\n",
    "        prediction_mask += [1] + [0] * (len(tokens) - 1)\n",
    "        \n",
    "    prediction_mask = prediction_mask[:len(entities)]\n",
    "        \n",
    "    assert len(prediction_mask) == len(entities)\n",
    "        \n",
    "    # eos\n",
    "    source_tokens += [tokenizer.eos_token]\n",
    "    entities += [tokenizer.eos_token]\n",
    "    attention_mask += [1]\n",
    "    prediction_mask += [0]\n",
    "    \n",
    "    # padding\n",
    "    missing = max(0, max_length - len(source_tokens))\n",
    "    source_tokens += [tokenizer.pad_token] * missing\n",
    "    attention_mask += [0] * missing\n",
    "    prediction_mask += [0] * missing\n",
    "    entities += [tokenizer.pad_token] * missing\n",
    "    \n",
    "    # to ids\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(source_tokens)\n",
    "    \n",
    "    # label_ids\n",
    "    entities2ids = {k:i for i, k in enumerate(LABELS_TOKENS)}\n",
    "    label_ids = [entities2ids.get(ent, -100) for ent in entities]\n",
    "    \n",
    "    assert len(input_ids) == len(attention_mask) == len(label_ids) == len(prediction_mask) == max_length\n",
    "    \n",
    "    return InputFeatures(input_ids, attention_mask, label_ids, prediction_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = convert_example_to_features(ex, model.tokenizer, 320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Source: Peter Blackburn\n",
       "Target: Peter Blackburn <PER>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        \n",
    "    def __len__(self,):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        feat = self.features[idx]\n",
    "        input_ids = torch.tensor(feat.input_ids, dtype=torch.long)\n",
    "        attention_mask = torch.tensor(feat.attention_mask, dtype=torch.long)\n",
    "        label_ids = torch.tensor(feat.label_ids, dtype=torch.long)\n",
    "        prediction_mask = torch.tensor(feat.prediction_mask, dtype=torch.long)\n",
    "        return input_ids, attention_mask, label_ids, prediction_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewBase(ConfigBase):\n",
    "    \n",
    "    def _construct_examples_kwargs(self,):\n",
    "        kwargs = {}\n",
    "        return kwargs\n",
    "    \n",
    "    def get_features(self, examples):\n",
    "        kwargs = {\n",
    "            'max_length': self.max_length,\n",
    "        }\n",
    "        return [convert_example_to_features(ex, self.tokenizer, **kwargs) for ex in examples]\n",
    "    \n",
    "    def prepare_data(self,):\n",
    "        if not self._has_cached_datasets():\n",
    "            examples = self.get_examples()\n",
    "            train_features = self.get_features(examples['train'])\n",
    "            val_features = self.get_features(examples['valid'])\n",
    "            test_features = self.get_features(examples['test'])\n",
    "            \n",
    "            self.train_dataset = NERDataset(train_features)\n",
    "            self.val_dataset = NERDataset(val_features)\n",
    "            self.test_dataset = NERDataset(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New NER Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewNERBase(ModelForNERBase, NewBase):\n",
    "    \n",
    "    \n",
    "    def to_entities(self, samples):\n",
    "        return [\n",
    "            LABELS_TOKENS[y] for y in samples \n",
    "        ]\n",
    "    \n",
    "    def _handle_batch(self, batch):\n",
    "        input_ids, attention_mask, label_ids, prediction_mask = batch\n",
    "        outputs = self(input_ids=input_ids,\n",
    "                       attention_mask=attention_mask,\n",
    "                       label_ids=label_ids,\n",
    "                       prediction_mask=prediction_mask)\n",
    "        return outputs\n",
    "    \n",
    "    def _handle_eval_batch(self, batch):\n",
    "        outputs = self._handle_batch(batch)\n",
    "        active_labels = outputs[2]\n",
    "        active_logits = outputs[1]\n",
    "        \n",
    "        predicted_entities = active_logits.argmax(-1).cpu().numpy().tolist()\n",
    "        target_entities = active_labels.cpu().numpy().tolist()\n",
    "        \n",
    "        predicted_entities = self.to_entities(predicted_entities)\n",
    "        target_entities = self.to_entities(target_entities)\n",
    "        \n",
    "        return outputs, target_entities, predicted_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5EncoderForNER(nn.Module):\n",
    "    \n",
    "    def __init__(self, pretrained_path, num_labels, weight_O=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = T5Model.from_pretrained(pretrained_path)\n",
    "        self.num_labels = num_labels\n",
    "        \n",
    "        assert isinstance(weight_O, float) and 0 < weight_O < 1\n",
    "        weights = [weight_O] + [1.] * (num_labels - 1)\n",
    "        weights = torch.tensor(weights)\n",
    "        self.loss_fct = torch.nn.CrossEntropyLoss()\n",
    "        self.classifier = nn.Linear(self.model.config.hidden_size, num_labels)\n",
    "        \n",
    "    def active_logits_and_labels(self, logits, label_ids, prediction_mask=None):\n",
    "        # take the active logits\n",
    "        active_logits = logits.view(-1, self.num_labels)\n",
    "        # take the active labels\n",
    "        active_labels = label_ids.view(-1)\n",
    "        if prediction_mask is not None:\n",
    "            prediction_mask = prediction_mask.view(-1)\n",
    "            active_logits = active_logits[prediction_mask == 1]\n",
    "            active_labels = active_labels[prediction_mask == 1]\n",
    "        return active_logits, active_labels\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        label_ids=None,\n",
    "        prediction_mask=None,\n",
    "    ):\n",
    "\n",
    "        # Encode if needed (training, first prediction pass)\n",
    "        encoder_outputs = self.model.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "        )\n",
    "            \n",
    "        hidden_states = encoder_outputs[0]        \n",
    "        logits = self.classifier(hidden_states)\n",
    "        \n",
    "        outputs = (logits,)\n",
    "\n",
    "        if label_ids is not None:\n",
    "            active_logits, active_labels = self.active_logits_and_labels(\n",
    "                logits, label_ids, prediction_mask)\n",
    "            # calc the loss\n",
    "            loss = self.loss_fct(active_logits, active_labels)\n",
    "\n",
    "            outputs = (loss, active_logits, active_labels) + outputs\n",
    "            \n",
    "        return outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5PL(T5EncoderForNER, pl.LightningModule):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5ForNER(NewNERBase, T5PL):\n",
    "\n",
    "    def __init__(self, pretrained_path, num_labels, hparams):\n",
    "        super(T5PL, self).__init__(pretrained_path, num_labels)\n",
    "\n",
    "        self.hparams = hparams\n",
    "\n",
    "        self.tokenizer = self.get_tokenizer()\n",
    "        \n",
    "        self.train_dataset = None\n",
    "        self.val_dataset = None\n",
    "        self.test_dataset = None\n",
    "\n",
    "    def get_tokenizer(self,):\n",
    "        pretrained_model = self.get_value_or_default_hparam(\n",
    "            'pretrained_model', 't5-small')\n",
    "        return T5Tokenizer.from_pretrained(pretrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Conll2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewConll2003Base:\n",
    "    @property\n",
    "    def entities_tokens(self):\n",
    "        return [\n",
    "            '<O>',\n",
    "            '<PER>',\n",
    "            '<ORG>',\n",
    "            '<LOC>',\n",
    "            '<MISC>',\n",
    "            '<Ent>'\n",
    "        ]\n",
    "\n",
    "    @property\n",
    "    def labels2words(self,):\n",
    "        return {\n",
    "            'O': '[Other]',\n",
    "            'PER': '[Person]',\n",
    "            'LOC': '[Local]',\n",
    "            'MISC': '[Miscellaneous]',\n",
    "            'ORG': '[Organization]',\n",
    "            'Ent': '[Ent]'\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def entities2tokens(self,):\n",
    "        return{\n",
    "            '[Other]': '<O>',\n",
    "            '[Person]': '<PER>',\n",
    "            '[Local]': '<LOC>',\n",
    "            '[Miscellaneous]': '<MISC>',\n",
    "            '[Organization]': '<ORG>',\n",
    "            '[Ent]': '<Ent>'\n",
    "        }\n",
    "    \n",
    "    def get_tokenizer(self,):\n",
    "        tokenizer = super().get_tokenizer()\n",
    "        tokenizer.add_tokens(self.entities_tokens)\n",
    "        return tokenizer\n",
    "    \n",
    "    def get_examples(self,):\n",
    "        kwargs = self._construct_examples_kwargs()\n",
    "        return get_example_sets(self.datapath, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewT5ForConll2003(NewConll2003Base, T5ForNER):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"max_length\": 320\n",
    "}\n",
    "hparams = Namespace(**hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NewT5ForConll2003('t5-small', num_labels=9, hparams=hparams)\n",
    "# model = T5EncoderForNER('t5-small', num_labels=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.arange(32).unsqueeze(0)\n",
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "logits = model(input_ids)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running in fast_dev_run mode: will run a full train, val and test loop using a single batch\n",
      "GPU available: True, used: False\n",
      "No environment variable for node rank defined. Set as 0.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(fast_dev_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    | Name                                                                  | Type                  | Params\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "0   | model                                                                 | T5Model               | 60 M  \n",
      "1   | model.shared                                                          | Embedding             | 16 M  \n",
      "2   | model.encoder                                                         | T5Stack               | 35 M  \n",
      "3   | model.encoder.block                                                   | ModuleList            | 18 M  \n",
      "4   | model.encoder.block.0                                                 | T5Block               | 3 M   \n",
      "5   | model.encoder.block.0.layer                                           | ModuleList            | 3 M   \n",
      "6   | model.encoder.block.0.layer.0                                         | T5LayerSelfAttention  | 1 M   \n",
      "7   | model.encoder.block.0.layer.0.SelfAttention                           | T5Attention           | 1 M   \n",
      "8   | model.encoder.block.0.layer.0.SelfAttention.q                         | Linear                | 262 K \n",
      "9   | model.encoder.block.0.layer.0.SelfAttention.k                         | Linear                | 262 K \n",
      "10  | model.encoder.block.0.layer.0.SelfAttention.v                         | Linear                | 262 K \n",
      "11  | model.encoder.block.0.layer.0.SelfAttention.o                         | Linear                | 262 K \n",
      "12  | model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias   | Embedding             | 256   \n",
      "13  | model.encoder.block.0.layer.0.layer_norm                              | T5LayerNorm           | 512   \n",
      "14  | model.encoder.block.0.layer.0.dropout                                 | Dropout               | 0     \n",
      "15  | model.encoder.block.0.layer.1                                         | T5LayerFF             | 2 M   \n",
      "16  | model.encoder.block.0.layer.1.DenseReluDense                          | T5DenseReluDense      | 2 M   \n",
      "17  | model.encoder.block.0.layer.1.DenseReluDense.wi                       | Linear                | 1 M   \n",
      "18  | model.encoder.block.0.layer.1.DenseReluDense.wo                       | Linear                | 1 M   \n",
      "19  | model.encoder.block.0.layer.1.DenseReluDense.dropout                  | Dropout               | 0     \n",
      "20  | model.encoder.block.0.layer.1.layer_norm                              | T5LayerNorm           | 512   \n",
      "21  | model.encoder.block.0.layer.1.dropout                                 | Dropout               | 0     \n",
      "22  | model.encoder.block.1                                                 | T5Block               | 3 M   \n",
      "23  | model.encoder.block.1.layer                                           | ModuleList            | 3 M   \n",
      "24  | model.encoder.block.1.layer.0                                         | T5LayerSelfAttention  | 1 M   \n",
      "25  | model.encoder.block.1.layer.0.SelfAttention                           | T5Attention           | 1 M   \n",
      "26  | model.encoder.block.1.layer.0.SelfAttention.q                         | Linear                | 262 K \n",
      "27  | model.encoder.block.1.layer.0.SelfAttention.k                         | Linear                | 262 K \n",
      "28  | model.encoder.block.1.layer.0.SelfAttention.v                         | Linear                | 262 K \n",
      "29  | model.encoder.block.1.layer.0.SelfAttention.o                         | Linear                | 262 K \n",
      "30  | model.encoder.block.1.layer.0.layer_norm                              | T5LayerNorm           | 512   \n",
      "31  | model.encoder.block.1.layer.0.dropout                                 | Dropout               | 0     \n",
      "32  | model.encoder.block.1.layer.1                                         | T5LayerFF             | 2 M   \n",
      "33  | model.encoder.block.1.layer.1.DenseReluDense                          | T5DenseReluDense      | 2 M   \n",
      "34  | model.encoder.block.1.layer.1.DenseReluDense.wi                       | Linear                | 1 M   \n",
      "35  | model.encoder.block.1.layer.1.DenseReluDense.wo                       | Linear                | 1 M   \n",
      "36  | model.encoder.block.1.layer.1.DenseReluDense.dropout                  | Dropout               | 0     \n",
      "37  | model.encoder.block.1.layer.1.layer_norm                              | T5LayerNorm           | 512   \n",
      "38  | model.encoder.block.1.layer.1.dropout                                 | Dropout               | 0     \n",
      "39  | model.encoder.block.2                                                 | T5Block               | 3 M   \n",
      "40  | model.encoder.block.2.layer                                           | ModuleList            | 3 M   \n",
      "41  | model.encoder.block.2.layer.0                                         | T5LayerSelfAttention  | 1 M   \n",
      "42  | model.encoder.block.2.layer.0.SelfAttention                           | T5Attention           | 1 M   \n",
      "43  | model.encoder.block.2.layer.0.SelfAttention.q                         | Linear                | 262 K \n",
      "44  | model.encoder.block.2.layer.0.SelfAttention.k                         | Linear                | 262 K \n",
      "45  | model.encoder.block.2.layer.0.SelfAttention.v                         | Linear                | 262 K \n",
      "46  | model.encoder.block.2.layer.0.SelfAttention.o                         | Linear                | 262 K \n",
      "47  | model.encoder.block.2.layer.0.layer_norm                              | T5LayerNorm           | 512   \n",
      "48  | model.encoder.block.2.layer.0.dropout                                 | Dropout               | 0     \n",
      "49  | model.encoder.block.2.layer.1                                         | T5LayerFF             | 2 M   \n",
      "50  | model.encoder.block.2.layer.1.DenseReluDense                          | T5DenseReluDense      | 2 M   \n",
      "51  | model.encoder.block.2.layer.1.DenseReluDense.wi                       | Linear                | 1 M   \n",
      "52  | model.encoder.block.2.layer.1.DenseReluDense.wo                       | Linear                | 1 M   \n",
      "53  | model.encoder.block.2.layer.1.DenseReluDense.dropout                  | Dropout               | 0     \n",
      "54  | model.encoder.block.2.layer.1.layer_norm                              | T5LayerNorm           | 512   \n",
      "55  | model.encoder.block.2.layer.1.dropout                                 | Dropout               | 0     \n",
      "56  | model.encoder.block.3                                                 | T5Block               | 3 M   \n",
      "57  | model.encoder.block.3.layer                                           | ModuleList            | 3 M   \n",
      "58  | model.encoder.block.3.layer.0                                         | T5LayerSelfAttention  | 1 M   \n",
      "59  | model.encoder.block.3.layer.0.SelfAttention                           | T5Attention           | 1 M   \n",
      "60  | model.encoder.block.3.layer.0.SelfAttention.q                         | Linear                | 262 K \n",
      "61  | model.encoder.block.3.layer.0.SelfAttention.k                         | Linear                | 262 K \n",
      "62  | model.encoder.block.3.layer.0.SelfAttention.v                         | Linear                | 262 K \n",
      "63  | model.encoder.block.3.layer.0.SelfAttention.o                         | Linear                | 262 K \n",
      "64  | model.encoder.block.3.layer.0.layer_norm                              | T5LayerNorm           | 512   \n",
      "65  | model.encoder.block.3.layer.0.dropout                                 | Dropout               | 0     \n",
      "66  | model.encoder.block.3.layer.1                                         | T5LayerFF             | 2 M   \n",
      "67  | model.encoder.block.3.layer.1.DenseReluDense                          | T5DenseReluDense      | 2 M   \n",
      "68  | model.encoder.block.3.layer.1.DenseReluDense.wi                       | Linear                | 1 M   \n",
      "69  | model.encoder.block.3.layer.1.DenseReluDense.wo                       | Linear                | 1 M   \n",
      "70  | model.encoder.block.3.layer.1.DenseReluDense.dropout                  | Dropout               | 0     \n",
      "71  | model.encoder.block.3.layer.1.layer_norm                              | T5LayerNorm           | 512   \n",
      "72  | model.encoder.block.3.layer.1.dropout                                 | Dropout               | 0     \n",
      "73  | model.encoder.block.4                                                 | T5Block               | 3 M   \n",
      "74  | model.encoder.block.4.layer                                           | ModuleList            | 3 M   \n",
      "75  | model.encoder.block.4.layer.0                                         | T5LayerSelfAttention  | 1 M   \n",
      "76  | model.encoder.block.4.layer.0.SelfAttention                           | T5Attention           | 1 M   \n",
      "77  | model.encoder.block.4.layer.0.SelfAttention.q                         | Linear                | 262 K \n",
      "78  | model.encoder.block.4.layer.0.SelfAttention.k                         | Linear                | 262 K \n",
      "79  | model.encoder.block.4.layer.0.SelfAttention.v                         | Linear                | 262 K \n",
      "80  | model.encoder.block.4.layer.0.SelfAttention.o                         | Linear                | 262 K \n",
      "81  | model.encoder.block.4.layer.0.layer_norm                              | T5LayerNorm           | 512   \n",
      "82  | model.encoder.block.4.layer.0.dropout                                 | Dropout               | 0     \n",
      "83  | model.encoder.block.4.layer.1                                         | T5LayerFF             | 2 M   \n",
      "84  | model.encoder.block.4.layer.1.DenseReluDense                          | T5DenseReluDense      | 2 M   \n",
      "85  | model.encoder.block.4.layer.1.DenseReluDense.wi                       | Linear                | 1 M   \n",
      "86  | model.encoder.block.4.layer.1.DenseReluDense.wo                       | Linear                | 1 M   \n",
      "87  | model.encoder.block.4.layer.1.DenseReluDense.dropout                  | Dropout               | 0     \n",
      "88  | model.encoder.block.4.layer.1.layer_norm                              | T5LayerNorm           | 512   \n",
      "89  | model.encoder.block.4.layer.1.dropout                                 | Dropout               | 0     \n",
      "90  | model.encoder.block.5                                                 | T5Block               | 3 M   \n",
      "91  | model.encoder.block.5.layer                                           | ModuleList            | 3 M   \n",
      "92  | model.encoder.block.5.layer.0                                         | T5LayerSelfAttention  | 1 M   \n",
      "93  | model.encoder.block.5.layer.0.SelfAttention                           | T5Attention           | 1 M   \n",
      "94  | model.encoder.block.5.layer.0.SelfAttention.q                         | Linear                | 262 K \n",
      "95  | model.encoder.block.5.layer.0.SelfAttention.k                         | Linear                | 262 K \n",
      "96  | model.encoder.block.5.layer.0.SelfAttention.v                         | Linear                | 262 K \n",
      "97  | model.encoder.block.5.layer.0.SelfAttention.o                         | Linear                | 262 K \n",
      "98  | model.encoder.block.5.layer.0.layer_norm                              | T5LayerNorm           | 512   \n",
      "99  | model.encoder.block.5.layer.0.dropout                                 | Dropout               | 0     \n",
      "100 | model.encoder.block.5.layer.1                                         | T5LayerFF             | 2 M   \n",
      "101 | model.encoder.block.5.layer.1.DenseReluDense                          | T5DenseReluDense      | 2 M   \n",
      "102 | model.encoder.block.5.layer.1.DenseReluDense.wi                       | Linear                | 1 M   \n",
      "103 | model.encoder.block.5.layer.1.DenseReluDense.wo                       | Linear                | 1 M   \n",
      "104 | model.encoder.block.5.layer.1.DenseReluDense.dropout                  | Dropout               | 0     \n",
      "105 | model.encoder.block.5.layer.1.layer_norm                              | T5LayerNorm           | 512   \n",
      "106 | model.encoder.block.5.layer.1.dropout                                 | Dropout               | 0     \n",
      "107 | model.encoder.final_layer_norm                                        | T5LayerNorm           | 512   \n",
      "108 | model.encoder.dropout                                                 | Dropout               | 0     \n",
      "109 | model.decoder                                                         | T5Stack               | 41 M  \n",
      "110 | model.decoder.block                                                   | ModuleList            | 25 M  \n",
      "111 | model.decoder.block.0                                                 | T5Block               | 4 M   \n",
      "112 | model.decoder.block.0.layer                                           | ModuleList            | 4 M   \n",
      "113 | model.decoder.block.0.layer.0                                         | T5LayerSelfAttention  | 1 M   \n",
      "114 | model.decoder.block.0.layer.0.SelfAttention                           | T5Attention           | 1 M   \n",
      "115 | model.decoder.block.0.layer.0.SelfAttention.q                         | Linear                | 262 K \n",
      "116 | model.decoder.block.0.layer.0.SelfAttention.k                         | Linear                | 262 K \n",
      "117 | model.decoder.block.0.layer.0.SelfAttention.v                         | Linear                | 262 K \n",
      "118 | model.decoder.block.0.layer.0.SelfAttention.o                         | Linear                | 262 K \n",
      "119 | model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias   | Embedding             | 256   \n",
      "120 | model.decoder.block.0.layer.0.layer_norm                              | T5LayerNorm           | 512   \n",
      "121 | model.decoder.block.0.layer.0.dropout                                 | Dropout               | 0     \n",
      "122 | model.decoder.block.0.layer.1                                         | T5LayerCrossAttention | 1 M   \n",
      "123 | model.decoder.block.0.layer.1.EncDecAttention                         | T5Attention           | 1 M   \n",
      "124 | model.decoder.block.0.layer.1.EncDecAttention.q                       | Linear                | 262 K \n",
      "125 | model.decoder.block.0.layer.1.EncDecAttention.k                       | Linear                | 262 K \n",
      "126 | model.decoder.block.0.layer.1.EncDecAttention.v                       | Linear                | 262 K \n",
      "127 | model.decoder.block.0.layer.1.EncDecAttention.o                       | Linear                | 262 K \n",
      "128 | model.decoder.block.0.layer.1.EncDecAttention.relative_attention_bias | Embedding             | 256   \n",
      "129 | model.decoder.block.0.layer.1.layer_norm                              | T5LayerNorm           | 512   \n",
      "130 | model.decoder.block.0.layer.1.dropout                                 | Dropout               | 0     \n",
      "131 | model.decoder.block.0.layer.2                                         | T5LayerFF             | 2 M   \n",
      "132 | model.decoder.block.0.layer.2.DenseReluDense                          | T5DenseReluDense      | 2 M   \n",
      "133 | model.decoder.block.0.layer.2.DenseReluDense.wi                       | Linear                | 1 M   \n",
      "134 | model.decoder.block.0.layer.2.DenseReluDense.wo                       | Linear                | 1 M   \n",
      "135 | model.decoder.block.0.layer.2.DenseReluDense.dropout                  | Dropout               | 0     \n",
      "136 | model.decoder.block.0.layer.2.layer_norm                              | T5LayerNorm           | 512   \n",
      "137 | model.decoder.block.0.layer.2.dropout                                 | Dropout               | 0     \n",
      "138 | model.decoder.block.1                                                 | T5Block               | 4 M   \n",
      "139 | model.decoder.block.1.layer                                           | ModuleList            | 4 M   \n",
      "140 | model.decoder.block.1.layer.0                                         | T5LayerSelfAttention  | 1 M   \n",
      "141 | model.decoder.block.1.layer.0.SelfAttention                           | T5Attention           | 1 M   \n",
      "142 | model.decoder.block.1.layer.0.SelfAttention.q                         | Linear                | 262 K \n",
      "143 | model.decoder.block.1.layer.0.SelfAttention.k                         | Linear                | 262 K \n",
      "144 | model.decoder.block.1.layer.0.SelfAttention.v                         | Linear                | 262 K \n",
      "145 | model.decoder.block.1.layer.0.SelfAttention.o                         | Linear                | 262 K \n",
      "146 | model.decoder.block.1.layer.0.layer_norm                              | T5LayerNorm           | 512   \n",
      "147 | model.decoder.block.1.layer.0.dropout                                 | Dropout               | 0     \n",
      "148 | model.decoder.block.1.layer.1                                         | T5LayerCrossAttention | 1 M   \n",
      "149 | model.decoder.block.1.layer.1.EncDecAttention                         | T5Attention           | 1 M   \n",
      "150 | model.decoder.block.1.layer.1.EncDecAttention.q                       | Linear                | 262 K \n",
      "151 | model.decoder.block.1.layer.1.EncDecAttention.k                       | Linear                | 262 K \n",
      "152 | model.decoder.block.1.layer.1.EncDecAttention.v                       | Linear                | 262 K \n",
      "153 | model.decoder.block.1.layer.1.EncDecAttention.o                       | Linear                | 262 K \n",
      "154 | model.decoder.block.1.layer.1.layer_norm                              | T5LayerNorm           | 512   \n",
      "155 | model.decoder.block.1.layer.1.dropout                                 | Dropout               | 0     \n",
      "156 | model.decoder.block.1.layer.2                                         | T5LayerFF             | 2 M   \n",
      "157 | model.decoder.block.1.layer.2.DenseReluDense                          | T5DenseReluDense      | 2 M   \n",
      "158 | model.decoder.block.1.layer.2.DenseReluDense.wi                       | Linear                | 1 M   \n",
      "159 | model.decoder.block.1.layer.2.DenseReluDense.wo                       | Linear                | 1 M   \n",
      "160 | model.decoder.block.1.layer.2.DenseReluDense.dropout                  | Dropout               | 0     \n",
      "161 | model.decoder.block.1.layer.2.layer_norm                              | T5LayerNorm           | 512   \n",
      "162 | model.decoder.block.1.layer.2.dropout                                 | Dropout               | 0     \n",
      "163 | model.decoder.block.2                                                 | T5Block               | 4 M   \n",
      "164 | model.decoder.block.2.layer                                           | ModuleList            | 4 M   \n",
      "165 | model.decoder.block.2.layer.0                                         | T5LayerSelfAttention  | 1 M   \n",
      "166 | model.decoder.block.2.layer.0.SelfAttention                           | T5Attention           | 1 M   \n",
      "167 | model.decoder.block.2.layer.0.SelfAttention.q                         | Linear                | 262 K \n",
      "168 | model.decoder.block.2.layer.0.SelfAttention.k                         | Linear                | 262 K \n",
      "169 | model.decoder.block.2.layer.0.SelfAttention.v                         | Linear                | 262 K \n",
      "170 | model.decoder.block.2.layer.0.SelfAttention.o                         | Linear                | 262 K \n",
      "171 | model.decoder.block.2.layer.0.layer_norm                              | T5LayerNorm           | 512   \n",
      "172 | model.decoder.block.2.layer.0.dropout                                 | Dropout               | 0     \n",
      "173 | model.decoder.block.2.layer.1                                         | T5LayerCrossAttention | 1 M   \n",
      "174 | model.decoder.block.2.layer.1.EncDecAttention                         | T5Attention           | 1 M   \n",
      "175 | model.decoder.block.2.layer.1.EncDecAttention.q                       | Linear                | 262 K \n",
      "176 | model.decoder.block.2.layer.1.EncDecAttention.k                       | Linear                | 262 K \n",
      "177 | model.decoder.block.2.layer.1.EncDecAttention.v                       | Linear                | 262 K \n",
      "178 | model.decoder.block.2.layer.1.EncDecAttention.o                       | Linear                | 262 K \n",
      "179 | model.decoder.block.2.layer.1.layer_norm                              | T5LayerNorm           | 512   \n",
      "180 | model.decoder.block.2.layer.1.dropout                                 | Dropout               | 0     \n",
      "181 | model.decoder.block.2.layer.2                                         | T5LayerFF             | 2 M   \n",
      "182 | model.decoder.block.2.layer.2.DenseReluDense                          | T5DenseReluDense      | 2 M   \n",
      "183 | model.decoder.block.2.layer.2.DenseReluDense.wi                       | Linear                | 1 M   \n",
      "184 | model.decoder.block.2.layer.2.DenseReluDense.wo                       | Linear                | 1 M   \n",
      "185 | model.decoder.block.2.layer.2.DenseReluDense.dropout                  | Dropout               | 0     \n",
      "186 | model.decoder.block.2.layer.2.layer_norm                              | T5LayerNorm           | 512   \n",
      "187 | model.decoder.block.2.layer.2.dropout                                 | Dropout               | 0     \n",
      "188 | model.decoder.block.3                                                 | T5Block               | 4 M   \n",
      "189 | model.decoder.block.3.layer                                           | ModuleList            | 4 M   \n",
      "190 | model.decoder.block.3.layer.0                                         | T5LayerSelfAttention  | 1 M   \n",
      "191 | model.decoder.block.3.layer.0.SelfAttention                           | T5Attention           | 1 M   \n",
      "192 | model.decoder.block.3.layer.0.SelfAttention.q                         | Linear                | 262 K \n",
      "193 | model.decoder.block.3.layer.0.SelfAttention.k                         | Linear                | 262 K \n",
      "194 | model.decoder.block.3.layer.0.SelfAttention.v                         | Linear                | 262 K \n",
      "195 | model.decoder.block.3.layer.0.SelfAttention.o                         | Linear                | 262 K \n",
      "196 | model.decoder.block.3.layer.0.layer_norm                              | T5LayerNorm           | 512   \n",
      "197 | model.decoder.block.3.layer.0.dropout                                 | Dropout               | 0     \n",
      "198 | model.decoder.block.3.layer.1                                         | T5LayerCrossAttention | 1 M   \n",
      "199 | model.decoder.block.3.layer.1.EncDecAttention                         | T5Attention           | 1 M   \n",
      "200 | model.decoder.block.3.layer.1.EncDecAttention.q                       | Linear                | 262 K \n",
      "201 | model.decoder.block.3.layer.1.EncDecAttention.k                       | Linear                | 262 K \n",
      "202 | model.decoder.block.3.layer.1.EncDecAttention.v                       | Linear                | 262 K \n",
      "203 | model.decoder.block.3.layer.1.EncDecAttention.o                       | Linear                | 262 K \n",
      "204 | model.decoder.block.3.layer.1.layer_norm                              | T5LayerNorm           | 512   \n",
      "205 | model.decoder.block.3.layer.1.dropout                                 | Dropout               | 0     \n",
      "206 | model.decoder.block.3.layer.2                                         | T5LayerFF             | 2 M   \n",
      "207 | model.decoder.block.3.layer.2.DenseReluDense                          | T5DenseReluDense      | 2 M   \n",
      "208 | model.decoder.block.3.layer.2.DenseReluDense.wi                       | Linear                | 1 M   \n",
      "209 | model.decoder.block.3.layer.2.DenseReluDense.wo                       | Linear                | 1 M   \n",
      "210 | model.decoder.block.3.layer.2.DenseReluDense.dropout                  | Dropout               | 0     \n",
      "211 | model.decoder.block.3.layer.2.layer_norm                              | T5LayerNorm           | 512   \n",
      "212 | model.decoder.block.3.layer.2.dropout                                 | Dropout               | 0     \n",
      "213 | model.decoder.block.4                                                 | T5Block               | 4 M   \n",
      "214 | model.decoder.block.4.layer                                           | ModuleList            | 4 M   \n",
      "215 | model.decoder.block.4.layer.0                                         | T5LayerSelfAttention  | 1 M   \n",
      "216 | model.decoder.block.4.layer.0.SelfAttention                           | T5Attention           | 1 M   \n",
      "217 | model.decoder.block.4.layer.0.SelfAttention.q                         | Linear                | 262 K \n",
      "218 | model.decoder.block.4.layer.0.SelfAttention.k                         | Linear                | 262 K \n",
      "219 | model.decoder.block.4.layer.0.SelfAttention.v                         | Linear                | 262 K \n",
      "220 | model.decoder.block.4.layer.0.SelfAttention.o                         | Linear                | 262 K \n",
      "221 | model.decoder.block.4.layer.0.layer_norm                              | T5LayerNorm           | 512   \n",
      "222 | model.decoder.block.4.layer.0.dropout                                 | Dropout               | 0     \n",
      "223 | model.decoder.block.4.layer.1                                         | T5LayerCrossAttention | 1 M   \n",
      "224 | model.decoder.block.4.layer.1.EncDecAttention                         | T5Attention           | 1 M   \n",
      "225 | model.decoder.block.4.layer.1.EncDecAttention.q                       | Linear                | 262 K \n",
      "226 | model.decoder.block.4.layer.1.EncDecAttention.k                       | Linear                | 262 K \n",
      "227 | model.decoder.block.4.layer.1.EncDecAttention.v                       | Linear                | 262 K \n",
      "228 | model.decoder.block.4.layer.1.EncDecAttention.o                       | Linear                | 262 K \n",
      "229 | model.decoder.block.4.layer.1.layer_norm                              | T5LayerNorm           | 512   \n",
      "230 | model.decoder.block.4.layer.1.dropout                                 | Dropout               | 0     \n",
      "231 | model.decoder.block.4.layer.2                                         | T5LayerFF             | 2 M   \n",
      "232 | model.decoder.block.4.layer.2.DenseReluDense                          | T5DenseReluDense      | 2 M   \n",
      "233 | model.decoder.block.4.layer.2.DenseReluDense.wi                       | Linear                | 1 M   \n",
      "234 | model.decoder.block.4.layer.2.DenseReluDense.wo                       | Linear                | 1 M   \n",
      "235 | model.decoder.block.4.layer.2.DenseReluDense.dropout                  | Dropout               | 0     \n",
      "236 | model.decoder.block.4.layer.2.layer_norm                              | T5LayerNorm           | 512   \n",
      "237 | model.decoder.block.4.layer.2.dropout                                 | Dropout               | 0     \n",
      "238 | model.decoder.block.5                                                 | T5Block               | 4 M   \n",
      "239 | model.decoder.block.5.layer                                           | ModuleList            | 4 M   \n",
      "240 | model.decoder.block.5.layer.0                                         | T5LayerSelfAttention  | 1 M   \n",
      "241 | model.decoder.block.5.layer.0.SelfAttention                           | T5Attention           | 1 M   \n",
      "242 | model.decoder.block.5.layer.0.SelfAttention.q                         | Linear                | 262 K \n",
      "243 | model.decoder.block.5.layer.0.SelfAttention.k                         | Linear                | 262 K \n",
      "244 | model.decoder.block.5.layer.0.SelfAttention.v                         | Linear                | 262 K \n",
      "245 | model.decoder.block.5.layer.0.SelfAttention.o                         | Linear                | 262 K \n",
      "246 | model.decoder.block.5.layer.0.layer_norm                              | T5LayerNorm           | 512   \n",
      "247 | model.decoder.block.5.layer.0.dropout                                 | Dropout               | 0     \n",
      "248 | model.decoder.block.5.layer.1                                         | T5LayerCrossAttention | 1 M   \n",
      "249 | model.decoder.block.5.layer.1.EncDecAttention                         | T5Attention           | 1 M   \n",
      "250 | model.decoder.block.5.layer.1.EncDecAttention.q                       | Linear                | 262 K \n",
      "251 | model.decoder.block.5.layer.1.EncDecAttention.k                       | Linear                | 262 K \n",
      "252 | model.decoder.block.5.layer.1.EncDecAttention.v                       | Linear                | 262 K \n",
      "253 | model.decoder.block.5.layer.1.EncDecAttention.o                       | Linear                | 262 K \n",
      "254 | model.decoder.block.5.layer.1.layer_norm                              | T5LayerNorm           | 512   \n",
      "255 | model.decoder.block.5.layer.1.dropout                                 | Dropout               | 0     \n",
      "256 | model.decoder.block.5.layer.2                                         | T5LayerFF             | 2 M   \n",
      "257 | model.decoder.block.5.layer.2.DenseReluDense                          | T5DenseReluDense      | 2 M   \n",
      "258 | model.decoder.block.5.layer.2.DenseReluDense.wi                       | Linear                | 1 M   \n",
      "259 | model.decoder.block.5.layer.2.DenseReluDense.wo                       | Linear                | 1 M   \n",
      "260 | model.decoder.block.5.layer.2.DenseReluDense.dropout                  | Dropout               | 0     \n",
      "261 | model.decoder.block.5.layer.2.layer_norm                              | T5LayerNorm           | 512   \n",
      "262 | model.decoder.block.5.layer.2.dropout                                 | Dropout               | 0     \n",
      "263 | model.decoder.final_layer_norm                                        | T5LayerNorm           | 512   \n",
      "264 | model.decoder.dropout                                                 | Dropout               | 0     \n",
      "265 | loss_fct                                                              | CrossEntropyLoss      | 0     \n",
      "266 | classifier                                                            | Linear                | 4 K   \n",
      "/home/israel/miniconda3/envs/t5ner/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/israel/miniconda3/envs/t5ner/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30614f2d997e40828179187d960d8a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), mâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "4\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(model.test_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "outputs = model._handle_batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1361)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:t5ner]",
   "language": "python",
   "name": "conda-env-t5ner-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
